{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_taxonomy\n",
    "\n",
    "filename = \"cais_data_expanded.csv\"\n",
    "brand_terms = [\n",
    "    \"cais\",\n",
    "    \"cais group\",\n",
    "    \"glas\",\n",
    "    \"glas funds\",\n",
    "    \"halo\",\n",
    "    \"halo investing\",\n",
    "    \"icapital\",\n",
    "    \"icapital network\",\n",
    "]\n",
    "website_subject = \"Alternate Investing Platform\"\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(\n",
    "    filename,\n",
    "    text_column=\"keyword\",\n",
    "    search_volume_column=\"search_volume\",\n",
    "    min_df=5,\n",
    "    brand_terms=brand_terms,\n",
    ")\n",
    "\n",
    "df.to_csv(\"cais_data_taxonomy.csv\", index=False)\n",
    "\n",
    "print(\"\\n\".join(taxonomy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_taxonomy\n",
    "\n",
    "filename = \"HM Raw Data.csv\"\n",
    "website_subject = \"Houston Methodist Hospital\"\n",
    "\n",
    "brand_terms = [\n",
    "    \"luke\",\n",
    "    \"lukes\",\n",
    "    \"md anderson\",\n",
    "    \"anderson\",\n",
    "    \"hca\",\n",
    "    \"stlukes\",\n",
    "    \"memorial hermann\",\n",
    "    \"hermann\",\n",
    "    \"herman\",\n",
    "    \"houston methodist\",\n",
    "    \"methodist\",\n",
    "    \"st joseph\",\n",
    "    \"joseph\",\n",
    "]\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(\n",
    "    filename,\n",
    "    website_subject=website_subject,\n",
    "    text_column=\"keyword\",\n",
    "    search_volume_column=\"search_volume\",\n",
    "    min_cluster_size=10,\n",
    "    min_samples=3,\n",
    "    limit_queries=3,\n",
    "    ngram_range=(1, 5),\n",
    "    min_df=10,\n",
    "    brand_terms=brand_terms,\n",
    ")\n",
    "\n",
    "\n",
    "df.to_csv(\"HM_Raw_Data_ngram_taxonomy2.csv\", index=False)\n",
    "print(\"\\n\".join(taxonomy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a GSC Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2023-07-21 08:59:41.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.searchconsole\u001b[0m:\u001b[36mload_gsc_account_data\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mCreating dataframe...\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.searchconsole\u001b[0m:\u001b[36mload_gsc_account_data\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mDataframe created.\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mGot Data. Dataframe shape: (2419, 7)\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m217\u001b[0m - \u001b[1mFiltering Query Data.\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mGot ngram frequency. Dataframe shape: (384, 2)\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mMerged Ngrams. Dataframe shape: (321, 4)\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:01.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mFinal score and filter length: 321\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:01.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1mGot ngram frequency. Dataframe shape: (321, 6)\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:01.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m224\u001b[0m - \u001b[1mGot query data as markdown. Length: 13888\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:01.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mUsing OpenAI API.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ngram_size    query  merged_frequency  frequency  search_volume     score\n",
      "0           1  lounger          1.000000   1.000000       1.000000  1.000000\n",
      "1           1     pool          0.154122   0.690695       0.836386  0.495254\n",
      "2           1     hole          0.014337   0.013106       0.560620  0.287479\n",
      "3           1    table          0.111111   0.328965       0.423304  0.267208\n",
      "4           1  outdoor          0.301075   0.250328       0.218655  0.259865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-21 09:00:10.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mReviewing OpenAI's work.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m254\u001b[0m - \u001b[1mGetting structure.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mAdding categories.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mGetting embeddings.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "Batches: 100%|██████████| 22/22 [00:02<00:00,  7.50it/s]\n",
      "\u001b[32m2023-07-21 09:00:21.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:21.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:22.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m496\u001b[0m - \u001b[1mGetting pairwise cosine similarity.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:22.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m499\u001b[0m - \u001b[1mGetting cross-encoder similarity.\u001b[0m\n",
      "Getting cross-encoder similarity: 100%|██████████| 1384/1384 [04:04<00:00,  5.65it/s]\n",
      "\u001b[32m2023-07-21 09:04:29.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mDone.\u001b[0m\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'ledgeloungers_taxonomy.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m      5\u001b[0m website_subject \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLedge Lounger offers luxury pool & outdoor furniture designed to create perfect spaces for outdoor entertaining and relaxation.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m taxonomy, df, samples \u001b[39m=\u001b[39m create_taxonomy(\n\u001b[0;32m      8\u001b[0m     \u001b[39mproperty\u001b[39m,\n\u001b[0;32m      9\u001b[0m     website_subject\u001b[39m=\u001b[39mwebsite_subject,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     limit_queries_per_page\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m\"\u001b[39;49m\u001b[39mledgeloungers_taxonomy.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     21\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'ledgeloungers_taxonomy.csv'"
     ]
    }
   ],
   "source": [
    "from main import create_taxonomy\n",
    "\n",
    "brand_terms = [\"ledgeloungers\", \"ledge\"]\n",
    "property = \"sc-domain:ledgeloungers.com\"\n",
    "website_subject = \"Ledge Lounger offers luxury pool & outdoor furniture designed to create perfect spaces for outdoor entertaining and relaxation.\"\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(\n",
    "    property,\n",
    "    website_subject=website_subject,\n",
    "    days=30,\n",
    "    ngram_range=(1, 5),\n",
    "    cross_encoded=True,\n",
    "    min_df=5,\n",
    "    brand_terms=brand_terms,\n",
    "    limit_queries_per_page=5,\n",
    ")\n",
    "\n",
    "\n",
    "df.to_csv(\"ledgeloungers_taxonomy2.csv\", index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ledgeloungers_taxonomy2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-21 07:28:42.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 07:28:42.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-21 07:28:43.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 07:28:43.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lib.clustering import ClusterTopics\n",
    "\n",
    "df = pd.read_csv(\"ledgeloungers_taxonomy.csv\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "queries = list(set(df[\"query\"].tolist()))\n",
    "queries = [queries[idx] for idx in [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]]\n",
    "taxonomies = list(set(df[\"taxonomy\"].tolist()))\n",
    "\n",
    "cluster_model = ClusterTopics(cluster_categories=taxonomies)\n",
    "cluster_model.corpus = queries\n",
    "cluster_model.embeddings = cluster_model.get_embeddings(queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-21 07:28:49.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 07:28:49.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "category_embeddings = cluster_model.get_embeddings(taxonomies)\n",
    "query_embeddings = cluster_model.embeddings\n",
    "\n",
    "query_embeddings = query_embeddings / np.linalg.norm(query_embeddings, axis=1, keepdims=True)\n",
    "category_embeddings = category_embeddings / np.linalg.norm(category_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "cosine_similarity_matrix = cosine_similarity(query_embeddings, category_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = 10\n",
    "top_n = 5\n",
    "import settings\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/qnli-electra-base\")\n",
    "cross_encoder_pairs = []\n",
    "\n",
    "\n",
    "for idx, query in enumerate(queries):\n",
    "    #print(\"#\" * 50)\n",
    "    #print(f\"Query: {query}\")\n",
    "\n",
    "    #print(\"\\nCosine Similarity:\")\n",
    "    top_categories = np.argsort(cosine_similarity_matrix[idx])[-top_n:][::-1]\n",
    "    pairs = []\n",
    "    for i in top_categories:\n",
    "        #print(taxonomies[i], cosine_similarity_matrix[idx][i])\n",
    "        pairs.append((query, taxonomies[i]))\n",
    "    \n",
    "    cross_encoder_pairs.append(pairs)\n",
    "    #print()\n",
    "\n",
    "\n",
    "cross_encoder_similarity = np.array([\n",
    "            cross_encoder.predict(pairs).flatten()\n",
    "            for pairs in cross_encoder_pairs\n",
    "        ])\n",
    "\n",
    "for idx, query in enumerate(queries):\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Query: {query}\")\n",
    "\n",
    "    print(\"\\nCross-encoder Similarity:\")\n",
    "    \n",
    "    # Test cross_encoder_similarity scores for this query.  If all scores are high and similar, then the query is ambiguous.  If on score is considerably lower than the others, then the query is not ambiguous.\n",
    "    \n",
    "\n",
    "\n",
    "    top_category= np.argmin(cross_encoder_similarity[idx])\n",
    "    print(cross_encoder_pairs[idx][top_category][1], cross_encoder_similarity[idx][top_category])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: in the pool chairs\n",
      "Options:\n",
      "chairs pool chairs 7.287129\n",
      "pool furniture chairs 7.0691895\n",
      "pool furniture loungers 3.595707\n",
      "loungers pool loungers -2.3364563\n",
      "pool furniture accessories 2.3251443\n",
      "\n",
      "Best: chairs pool chairs, 7.287128925323486\n"
     ]
    }
   ],
   "source": [
    "import settings\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
    "\n",
    "query = \"in the pool chairs\"\n",
    "\n",
    "options = \"\"\"Chairs Pool Chairs\n",
    "Pool Furniture Chairs\n",
    "Pool Furniture Loungers\n",
    "Loungers Pool Loungers\n",
    "Pool Furniture Accessories\"\"\".split(\"\\n\")\n",
    "\n",
    "options = [o.lower() for o in options]\n",
    "\n",
    "cross_encoder_pairs = [(query, option) for option in options]\n",
    "\n",
    "cross_encoder_similarity = cross_encoder.predict(cross_encoder_pairs).flatten()\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Options:\")\n",
    "for idx, pair in enumerate(cross_encoder_pairs):\n",
    "    print(pair[1], cross_encoder_similarity[idx])\n",
    "\n",
    "print()\n",
    "print(f\"Best: {cross_encoder_pairs[np.argmax(cross_encoder_similarity)][1]}, {cross_encoder_similarity[np.argmax(cross_encoder_similarity)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2023-07-21 10:12:44.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:44.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mGetting embeddings.\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:46.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m496\u001b[0m - \u001b[1mGetting pairwise cosine similarity.\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:46.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m499\u001b[0m - \u001b[1mGetting cross-encoder similarity.\u001b[0m\n",
      "Getting cross-encoder similarity: 100%|██████████| 19/19 [00:01<00:00, 16.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from main import add_categories\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"ledgeloungers_taxonomy2.csv\")\n",
    "\n",
    "structure = list(set(df.taxonomy.tolist()))\n",
    "\n",
    "# Random sample of 10 df rows\n",
    "df = df.sample(20)\n",
    "\n",
    "df = add_categories(structure, df, \n",
    "                    cross_encoded=True, \n",
    "                    percentile_threshold=50,\n",
    "                    std_dev_threshold= 0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-24 16:21:37.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mGot ngram frequency. Dataframe shape: (7697, 2)\u001b[0m\n",
      "\u001b[32m2023-07-24 16:21:49.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mMerged Ngrams. Dataframe shape: (7004, 4)\u001b[0m\n",
      "Filtering by knee:   0%|          | 0/51 [00:00<?, ?it/s]\u001b[32m2023-07-24 16:30:03.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.nlp\u001b[0m:\u001b[36mfilter_knee\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mKnee found at 459 with S=1000\u001b[0m\n",
      "Filtering by knee:   2%|▏         | 1/51 [00:00<00:01, 38.46it/s]\n",
      "\u001b[32m2023-07-24 16:30:03.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mFiltered Knee (sensitivity=1005). Dataframe shape: (3000, 6)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_size</th>\n",
       "      <th>query</th>\n",
       "      <th>merged_frequency</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_volume</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>google</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>google says</td>\n",
       "      <td>0.578231</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.108810</td>\n",
       "      <td>0.343521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>google search</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.067480</td>\n",
       "      <td>0.309968</td>\n",
       "      <td>0.315698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>seo</td>\n",
       "      <td>0.465986</td>\n",
       "      <td>0.049218</td>\n",
       "      <td>0.063091</td>\n",
       "      <td>0.264539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>0.385204</td>\n",
       "      <td>0.053717</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.193350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ngram_size          query  merged_frequency  frequency  search_volume  \\\n",
       "0           1         google          1.000000   1.000000       1.000000   \n",
       "1           2    google says          0.578231   0.048684       0.108810   \n",
       "2           2  google search          0.321429   0.067480       0.309968   \n",
       "3           1            seo          0.465986   0.049218       0.063091   \n",
       "4           1          yahoo          0.385204   0.053717       0.001497   \n",
       "\n",
       "      score  \n",
       "0  1.000000  \n",
       "1  0.343521  \n",
       "2  0.315698  \n",
       "3  0.264539  \n",
       "4  0.193350  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from main import clean_provided_dataframe, score_and_filter_df\n",
    "\n",
    "df_raw = pd.read_csv(\"out_barry.csv\")\n",
    "df = df_raw.copy()\n",
    "df['query'] = df.title.copy()\n",
    "df['search_volume'] = df.ga_sessions.copy()\n",
    "\n",
    "df = clean_provided_dataframe(df, None, None)\n",
    "\n",
    "df = score_and_filter_df(df, min_df=5, min_length=3000)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"out_barry_ngrams4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from lib.api import get_openai_response_chat\n",
    "import settings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "df_entities = df_raw.copy().head(20)\n",
    "\n",
    "entities_found = set()\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for i, row in tqdm(df_entities.iterrows(), total=len(df_entities)):\n",
    "    \n",
    "    topic = row[\"title\"]\n",
    "    existing_entities = \"\\n\".join(entities_found)\n",
    "\n",
    "    prompt = f\"\"\"As an expert at SEO-subject detection in text content,\n",
    "    You will be given a topic and a list of existing subjects. The topics are content found on a popular SEO news site called SERoundtable.com. Your job to find key subjects related to SEO and online marketing found in the topic. \n",
    "    For example:\n",
    "      - Topic: google news suggested for you - to find sources, Subjects: Google News.\n",
    "      - Topic: google removes related search operator, Subjects: Google, Search Operators.\n",
    "      - Topic: google search central live indonesia event, Subjects: Google Search Central.\n",
    "      - Topic: bing chat gets visual search, Subjects: Bing Chat, Visual Search.\n",
    "    To keep things consistent, if the subject exists in the existing subjects, please use the subject from that list. Also, only use the singular form of subjects. Your output should be a comma-separated list of subjects in proper case. \n",
    "\n",
    "    Topic: {topic}\n",
    "\n",
    "    Existing subjects: {existing_entities}\n",
    "\n",
    "    Subjects: \"\"\"\n",
    "\n",
    "    explanation = get_openai_response_chat(\n",
    "        prompt,\n",
    "        model=settings.OPENAI_QUALITY_MODEL,\n",
    "        system_message=\"You are an expert subject detection in text content.\",\n",
    "    )\n",
    "\n",
    "    entities = [e.strip() for e in explanation.split(\",\")]\n",
    "    entities_found.update(entities)\n",
    "\n",
    "    result_dict[topic] = entities\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redirects, Technical SEO\n",
      "404 Errors, Technical SEO\n",
      "Ad Units, Paid Advertising\n",
      "Advertisers, Paid Advertising\n",
      "Affiliate Links, SEO Tactics\n",
      "Alexa, Analytics & Tools\n",
      "Google Update, Algorithm Update\n",
      "Algorithm Update, Algorithm Update\n",
      "Algorithms, Algorithm\n",
      "Alphabet, Company\n",
      "Alt Text, On-Page SEO\n",
      "Amit Singhal, Google Employees\n",
      "AMP, Mobile SEO\n",
      "Anchor Text, On-Page SEO\n",
      "Android, Mobile SEO\n",
      "AOL, Search Engines\n",
      "API, Technical SEO\n",
      "Apple, Company\n",
      "Article, Content\n",
      "Ask Jeeves, Search Engines\n",
      "Ask.com, Search Engines\n",
      "Attribution, SEO Tactics\n",
      "Author, On-Page SEO\n",
      "Authority, SEO Tactics\n",
      "Authorship, On-Page SEO\n",
      "Bard, Google Employees\n",
      "Barry Schwartz, SEO Community\n",
      "Bert, Algorithm Update\n",
      "Bing, Search Engines\n",
      "Bing Ads, Paid Advertising\n",
      "Bing Chat, Search Engines\n",
      "Bing Search, Search Engines\n",
      "Bing Search Results, Search Results\n",
      "Bing Shopping, Search Engines\n",
      "Bing Webmaster Tools, Analytics & Tools\n",
      "Bingbot, Bots\n",
      "Birthday, Google Events\n",
      "Black Hat, SEO Tactics\n",
      "Blogger, Content Management\n",
      "Bots, Bots\n",
      "Breadcrumbs, On-Page SEO\n",
      "Broad Match, Paid Advertising\n",
      "Business Listings, Local SEO\n",
      "Business Profile, Local SEO\n",
      "Buying Links, SEO Tactics\n",
      "Cache, Technical SEO\n",
      "Campaigns, Paid Advertising\n",
      "Canonical, Technical SEO\n",
      "Carousel, Search Results\n",
      "ChatGPT, Machine Learning\n",
      "Google Chrome, Browsers\n",
      "Apple Safari, Browsers\n",
      "Google Hummingbird Update, Algorithm Update\n",
      "Click Fraud, SEO Tactics\n",
      "Cloaking, SEO Tactics\n",
      "Conference, SEO Events\n",
      "Content, Content\n",
      "Core Updates, Algorithm Update\n",
      "Core Web Vitals, Technical SEO\n",
      "Covid 19, Google Events\n",
      "Crawling, Technical SEO\n",
      "CSS, Technical SEO\n",
      "CTR, SEO Metrics\n",
      "Danny Sullivan, Google Employees\n",
      "Desktop Search Results, Search Results\n",
      "Disallow, Technical SEO\n",
      "Disavow File, Technical SEO\n",
      "Disavow Links, Technical SEO\n",
      "DMOZ, Directories\n",
      "DNS, Technical SEO\n",
      "Dogpile, Search Engines\n",
      "Domains, Technical SEO\n",
      "Domain Name, Technical SEO\n",
      "Doodle, Google Events\n",
      "DuckDuckGo, Search Engines\n",
      "Duplicate Content, SEO Tactics\n",
      "Dynamic Search Ads, Paid Advertising\n",
      "Easter Egg, Google Events\n",
      "Ebay, E-commerce\n",
      "Emojis, On-Page SEO\n",
      "Eric Schmidt, Google Employees\n",
      "Evergreen Googlebot, Bots\n",
      "Experiments, SEO Tactics\n",
      "External Links, Off-Page SEO\n",
      "Facebook, Social Media\n",
      "Facebook Search, Social Media\n",
      "Favicon, On-Page SEO\n",
      "Featured Snippet, Search Results\n",
      "Firefox, Browsers\n",
      "Follow, Off-Page SEO\n",
      "Forums, SEO Community\n",
      "Gambling, SEO Tactics\n",
      "Gary Illyes, Google Employees\n",
      "Gmail, Google Products\n",
      "Google Ads, Paid Advertising\n",
      "Google Ads Editor, Paid Advertising\n",
      "Google Ads Performance, Paid Advertising\n",
      "Google Ads Search, Paid Advertising\n",
      "Google AdSense, Paid Advertising\n",
      "Google Adsense Account, Paid Advertising\n",
      "Google AdSense Ads, Paid Advertising\n",
      "Google AdSense Publishers, Paid Advertising\n",
      "Google AdWords, Paid Advertising\n",
      "Google AdWords Account, Paid Advertising\n",
      "Google AdWords Ads, Paid Advertising\n",
      "Google Adwords API, Paid Advertising\n",
      "Google AdWords Campaigns, Paid Advertising\n",
      "Google AdWords Editor, Paid Advertising\n",
      "Google Alerts, Analytics & Tools\n",
      "Google AMP, Mobile SEO\n",
      "Google Analytics, Analytics & Tools\n",
      "Google Android, Mobile SEO\n",
      "Google Answers, Search Engines\n",
      "Google API, Technical SEO\n",
      "Google App, Google Products\n",
      "Google App Indexing, Mobile SEO\n",
      "Google Assistant, Google Products\n",
      "Google Bard, Google Employees\n",
      "Google Blog Search, Search Engines\n",
      "Google My Business, Local SEO\n",
      "Google Business App, Google Products\n",
      "Google Business Insights, Local SEO\n",
      "Google Business Listings, Local SEO\n",
      "Google My Business App, Google Products\n",
      "Google My Business Insights, Local SEO\n",
      "Google My Business Listings, Local SEO\n",
      "Google My Business Profiles, Local SEO\n",
      "Google Business Profiles, Local SEO\n",
      "Google Cache, Technical SEO\n",
      "Google Caffeine, Algorithm\n",
      "Google Changes, Algorithm Update\n",
      "Google Checkout, E-commerce\n",
      "Google Dance, Algorithm Update\n",
      "Google Day, Google Events\n",
      "Google Desktop, Browsers\n",
      "Google Disavow Tool, Technical SEO\n",
      "Google Discover, Search Results\n",
      "Google Doodle, Google Events\n",
      "Google Earth, Google Products\n",
      "Google Fiber, Google Products\n",
      "Google Finance, Google Products\n",
      "Google Glass, Google Products\n",
      "Google Helpful Content Update, Algorithm Update\n",
      "Google Home, Google Products\n",
      "Google Home Page, Search Engines\n",
      "Google Images, Search Engines\n",
      "Google Instant, Search Engines\n",
      "Google Keyword Tool, SEO Tools\n",
      "Knowledge Graph, Search Results\n",
      "Google Lens, Google Products\n",
      "Google Local, Local SEO\n",
      "Google Local Business Center, Local SEO\n",
      "Google Local Maps, Local SEO\n",
      "Google Local Pack, Local SEO\n",
      "Google Local Panel, Local SEO\n",
      "Google Local Algorithm, Algorithm\n",
      "Google Local Algorithm Update, Algorithm Update\n",
      "Google Logo, Google Events\n",
      "Google Maps, Google Products\n",
      "Google Maps App, Google Products\n",
      "Google Maps Business, Google Products\n",
      "Google Maps Search, Google Products\n",
      "Google Medic Update, Algorithm Update\n",
      "Google Merchant Center, E-commerce\n",
      "Google Mobile, Mobile SEO\n",
      "Google Mobile Index, Mobile SEO\n",
      "Google News, News\n",
      "Google News Publishers, News\n",
      "Google Office, Google Events\n",
      "Google Page Experience Update, Algorithm Update\n",
      "Google PageRank Update, Algorithm Update\n",
      "Google Pages, Content Management\n",
      "Google Pagespeed Insights, Analytics & Tools\n",
      "Google Panda Update, Algorithm Update\n",
      "Google Partner, Google Employees\n",
      "Google Patent, SEO Tactics\n",
      "Google Penguin Update, Algorithm Update\n",
      "Google People Search, Search Engines\n",
      "Google Places, Local SEO\n",
      "Google Play, Google Products\n",
      "Google Plus, Social Media\n",
      "Google Plus Local, Social Media\n",
      "Google Product Reviews Update, Algorithm Update\n",
      "Google Product Search, E-commerce\n",
      "Google Rankings, SEO Metrics\n",
      "Google Reader, Content Management\n",
      "Google Real Time, Search Results\n",
      "Google Results, Search Results\n",
      "Google Reviews Update, Algorithm Update\n",
      "Google Rich Results, Search Results\n",
      "Google Sandbox, Algorithm\n",
      "Google Search, Search Engines\n",
      "Google Search Analytics, Analytics & Tools\n",
      "Google Search App, Search Engines\n",
      "Google Search Box, Search Engines\n",
      "Google Search Bug, Search Engines\n",
      "Google Search Console, Analytics & Tools\n",
      "Google Search Console API, Analytics & Tools\n",
      "Google Search Console Data, Analytics & Tools\n",
      "Google Search Console Reports, Analytics & Tools\n",
      "Google Search Results, Search Results\n",
      "Google Search Testing, SEO Tactics\n",
      "Google Self Driving Car, Google Products\n",
      "Google Shopping, E-commerce\n",
      "Google Shopping Ads, Paid Advertising\n",
      "Google Sitemaps, Technical SEO\n",
      "Google Spam, SEO Tactics\n",
      "Google Stories, Google Products\n",
      "Google Street View, Google Products\n",
      "Google Suggest, Search Engines\n",
      "Google Tests, SEO Tactics\n",
      "Google Toolbar, Browsers\n",
      "Google Translate, Google Products\n",
      "Google Trends, Analytics & Tools\n",
      "Google Videos, Search Engines\n",
      "Google Video Search, Search Engines\n",
      "Google Voice Search, Search Engines\n",
      "Google Webmaster Central, Analytics & Tools\n",
      "Google Webmaster Conference, SEO Events\n",
      "Google Webmaster Team, Google Employees\n",
      "Google Webmaster Report, Analytics & Tools\n",
      "Google Webmaster Tools, Analytics & Tools\n",
      "Google.com, Search Engines\n",
      "Googlebot, Bots\n",
      "Googleguy, Google Employees\n",
      "Googleplex, Google Offices\n",
      "Googlers, Google Employees\n",
      "Guest Blogging, SEO Tactics\n",
      "Hacked, SEO Tactics\n",
      "Headers, On-Page SEO\n",
      "Home Page, On-Page SEO\n",
      "Hosting, Technical SEO\n",
      "Hreflang, Technical SEO\n",
      "HTML5, Technical SEO\n",
      "Image Carousel, Search Results\n",
      "Google Image Search, Search Engines\n",
      "Image Search, Search Engines\n",
      "Images, On-Page SEO\n",
      "Indexing, Technical SEO\n",
      "IndexNow, Technical SEO\n",
      "Internal Links, On-Page SEO\n",
      "Internet Explorer, Browsers\n",
      "iOS, Mobile SEO\n",
      "IP Address, Technical SEO\n",
      "iPhone, Mobile SEO\n",
      "JavaScript, Technical SEO\n",
      "John Mueller, Google Employees\n",
      "Keyword Density, On-Page SEO\n",
      "Keyword Planner, SEO Tools\n",
      "Keywords, SEO Tactics\n",
      "Knowledge Panel, Search Results\n",
      "Knowledte Panel, Search Results\n",
      "Landing Pages, On-Page SEO\n",
      "Links, Off-Page SEO\n",
      "Link Building, Off-Page SEO\n",
      "Google Link Spam Update, Algorithm Update\n",
      "Google Local Business, Local SEO\n",
      "Local Knowledge Panel, Local SEO\n",
      "Local Listings, Local SEO\n",
      "Local Pack, Local SEO\n",
      "Local Results, Local SEO\n",
      "Google Local Results, Local SEO\n",
      "Google Local Search, Local SEO\n",
      "Google Local Service Ads, Local SEO\n",
      "Location, Local SEO\n",
      "Logo, On-Page SEO\n",
      "Low Quality, SEO Tactics\n",
      "AI, Machine Learning\n",
      "Machine Learning, Machine Learning\n",
      "Malware, Technical SEO\n",
      "Manual Actions, SEO Tactics\n",
      "Marissa Mayer, Google Employees\n",
      "Markup, On-Page SEO\n",
      "Martin Splitt, Google Employees\n",
      "Matt Cutts, Google Employees\n",
      "Meta, On-Page SEO\n",
      "Meta Descriptions, On-Page SEO\n",
      "Meta Tag, On-Page SEO\n",
      "Microsoft, Company\n",
      "Microsoft AdCenter, Paid Advertising\n",
      "Microsoft Advertising, Paid Advertising\n",
      "Microsoft Bing, Search Engines\n",
      "Microsoft Live Search, Search Engines\n",
      "Microsoft Search, Search Engines\n",
      "Mobile Friendly, Mobile SEO\n",
      "Mobile Friendly Algorithm, Algorithm Update\n",
      "Mobile Index, Mobile SEO\n",
      "Mobile Indexing, Mobile SEO\n",
      "Mobile Results, Mobile SEO\n",
      "Mountain View, Google Offices\n",
      "Moz, SEO Community\n",
      "Mozilla, Browsers\n",
      "MSN, Search Engines\n",
      "MSN AdCenter, Paid Advertising\n",
      "MSN Search Update, Algorithm Update\n",
      "MSN Search, Search Engines\n",
      "MSNbot, Bots\n",
      "Navigation Bar, On-Page SEO\n",
      "Negative SEO, SEO Tactics\n",
      "Nofollow, Off-Page SEO\n",
      "Noindex, On-Page SEO\n",
      "Organic Results, Organic Search\n",
      "Organic Search, Organic Search\n",
      "Overture, Paid Advertising\n",
      "Page Experience, On-Page SEO\n",
      "PageRank, SEO Metrics\n",
      "Paid Links, SEO Tactics\n",
      "PDFs, On-Page SEO\n",
      "Penalty, SEO Tactics\n",
      "Performance Max, Paid Advertising\n",
      "Performance Report, Analytics & Tools\n",
      "Pubcon, SEO Events\n",
      "Quality Content, SEO Tactics\n",
      "Quality Raters Guidelines, SEO Tactics\n",
      "Quality Score, Paid Advertising\n",
      "Rand Fishkin, SEO Community\n",
      "RankBrain, Algorithm\n",
      "Ranking Changes, Algorithm Update\n",
      "Ranking Factor, Algorithm\n",
      "Ranking Signal, Algorithm\n",
      "Rating, SEO Tactics\n",
      "Recipe, On-Page SEO\n",
      "Referrer, Technical SEO\n",
      "Results Page, Search Results\n",
      "Reviews, SEO Tactics\n",
      "Rich Snippets, Search Results\n",
      "Robots.txt, Technical SEO\n",
      "RSS, Content Management\n",
      "Sandbox, Algorithm\n",
      "Scams, SEO Tactics\n",
      "Schema, On-Page SEO\n",
      "Search Ads, Paid Advertising\n",
      "Search Box, Search Engines\n",
      "Search Community, SEO Community\n",
      "Search Community Honors, SEO Community\n",
      "Search Engines, Search Engines\n",
      "Search Engine Friendly, Technical SEO\n",
      "Search Engine Land, SEO Community\n",
      "Search Marketing, SEO Tactics\n",
      "Search Engine Roundtable, SEO Community\n",
      "Search Engine Watch, SEO Community\n",
      "Search Generative Experience, Search Engines\n",
      "Search History, Search Engines\n",
      "Search Quality, SEO Tactics\n",
      "Search Rankings, SEO Metrics\n",
      "Search Results, Search Results\n",
      "Search Suggestions, Search Engines\n",
      "Selling Links, SEO Tactics\n",
      "SEM, SEO Tactics\n",
      "SEMPO, SEO Community\n",
      "SEO, SEO Industry\n",
      "SEO Industry, SEO Industry\n",
      "SEOMoz, SEO Community\n",
      "Sergey Brin, Google Employees\n",
      "Service Ads, Paid Advertising\n",
      "Shopify, E-commerce\n",
      "Shopping Ads, Paid Advertising\n",
      "Signals, SEO Metrics\n",
      "Site Command, Technical SEO\n",
      "Sitelinks, On-Page SEO\n",
      "Sitemaps, Technical SEO\n",
      "SMX, SEO Events\n",
      "Snippets, Search Results\n",
      "Social Media, Social Media\n",
      "Spam, SEO Tactics\n",
      "Spam Algorithm, Algorithm\n",
      "Google Speed Update, Algorithm Update\n",
      "Google Backlink Update, Algorithm Update\n",
      "SSL, Technical SEO\n",
      "Status Code, Technical SEO\n",
      "Structured Data, On-Page SEO\n",
      "Sundar Pichai, Google Employees\n",
      "Tags, On-Page SEO\n",
      "Targeting, Paid Advertising\n",
      "Text Ads, Paid Advertising\n",
      "Theory, SEO Tactics\n",
      "Title Tags, On-Page SEO\n",
      "Titles, On-Page SEO\n",
      "TLDs, Technical SEO\n",
      "Topic, SEO Tactics\n",
      "Traffic, SEO Metrics\n",
      "Trending Searches, Search Engines\n",
      "Tweets, Social Media\n",
      "Twitter, Social Media\n",
      "Unnatural Links, SEO Tactics\n",
      "URLs, Technical SEO\n",
      "URL Inspection Tool, Technical SEO\n",
      "User Agent, Technical SEO\n",
      "Videos, Content\n",
      "Web Search, Search Engines\n",
      "Webmaster Central, Analytics & Tools\n",
      "Webmaster Guidelines, SEO Tactics\n",
      "Webmaster Report, Analytics & Tools\n",
      "Webmasters, SEO Community\n",
      "WebmasterWorld, SEO Community\n",
      "Webspam, SEO Tactics\n",
      "Widget, On-Page SEO\n",
      "Wikipedia, Search Engines\n",
      "Word Count, On-Page SEO\n",
      "Wordpress, Content Management\n",
      "XML Sitemaps, Technical SEO\n",
      "Yahoo, Search Engines\n",
      "Yahoo Directory, Directories\n",
      "Yahoo Publisher Network, Paid Advertising\n",
      "Yahoo Search, Search Engines\n",
      "Yahoo Search Marketing, Paid Advertising\n",
      "Yahoo Search Update, Algorithm Update\n",
      "Yahoo Site Explorer, Analytics & Tools\n",
      "Yandex, Search Engines\n",
      "Yelp, Local SEO\n",
      "YouTube, Video Marketing\n",
      "YouTube Videos, Video Marketing\n",
      "Keyword Research, SEO Tools\n",
      "Google Florida Update, Algorithm Update\n",
      "Google Toolbar PageRank Update, Algorithm Update\n",
      "Google Fred Update, Algorithm Update\n",
      "Google Farmer Update, Algorithm Update\n",
      "Google Maccabees Update, Algorithm Update\n",
      "Exact Match Domains, SEO Tactics\n",
      "Google Phantom Update, Algorithm Update\n"
     ]
    }
   ],
   "source": [
    "from lib.api import get_openai_response_chat\n",
    "import settings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ngrams = \"\"\"Redirects\n",
    "404 Errors\n",
    "Ad Units\n",
    "Advertisers\n",
    "Affiliate Links\n",
    "Alexa\n",
    "Google Update\n",
    "Algorithm Update\n",
    "Algorithms\n",
    "Alphabet\n",
    "Alt Text\n",
    "Amit Singhal\n",
    "AMP\n",
    "Anchor Text\n",
    "Android\n",
    "AOL\n",
    "API\n",
    "Apple\n",
    "Article\n",
    "Ask Jeeves\n",
    "Ask.com\n",
    "Attribution\n",
    "Author\n",
    "Authority\n",
    "Authorship\n",
    "Bard\n",
    "Barry Schwartz\n",
    "Bert\n",
    "Bing\n",
    "Bing Ads\n",
    "Bing Chat\n",
    "Bing Search\n",
    "Bing Search Results\n",
    "Bing Shopping\n",
    "Bing Webmaster Tools\n",
    "Bingbot\n",
    "Birthday\n",
    "Black Hat\n",
    "Blogger\n",
    "Bots\n",
    "Breadcrumbs\n",
    "Broad Match\n",
    "Business Listings\n",
    "Business Profile\n",
    "Buying Links\n",
    "Cache\n",
    "Campaigns\n",
    "Canonical\n",
    "Carousel\n",
    "ChatGPT\n",
    "Google Chrome\n",
    "Apple Safari\n",
    "Google Hummingbird Update\n",
    "Click Fraud\n",
    "Cloaking\n",
    "Conference\n",
    "Content\n",
    "Core Updates\n",
    "Core Web Vitals\n",
    "Covid 19\n",
    "Crawling\n",
    "CSS\n",
    "CTR\n",
    "Danny Sullivan\n",
    "Desktop Search Results\n",
    "Disallow\n",
    "Disavow File\n",
    "Disavow Links\n",
    "DMOZ\n",
    "DNS\n",
    "Dogpile\n",
    "Domains\n",
    "Domain Name\n",
    "Doodle\n",
    "DuckDuckGo\n",
    "Duplicate Content\n",
    "Dynamic Search Ads\n",
    "Easter Egg\n",
    "Ebay\n",
    "Emojis\n",
    "Eric Schmidt\n",
    "Evergreen Googlebot\n",
    "Experiments\n",
    "External Links\n",
    "Facebook\n",
    "Facebook Search\n",
    "Favicon\n",
    "Featured Snippet\n",
    "Firefox\n",
    "Follow\n",
    "Forums\n",
    "Gambling\n",
    "Gary Illyes\n",
    "Gmail\n",
    "Google Ads\n",
    "Google Ads Editor\n",
    "Google Ads Performance\n",
    "Google Ads Search\n",
    "Google AdSense\n",
    "Google Adsense Account\n",
    "Google AdSense Ads\n",
    "Google AdSense Publishers\n",
    "Google AdWords\n",
    "Google AdWords Account\n",
    "Google AdWords Ads\n",
    "Google Adwords API\n",
    "Google AdWords Campaigns\n",
    "Google AdWords Editor\n",
    "Google Alerts\n",
    "Google AMP\n",
    "Google Analytics\n",
    "Google Android\n",
    "Google Answers\n",
    "Google API\n",
    "Google App\n",
    "Google App Indexing\n",
    "Google Assistant\n",
    "Google Bard\n",
    "Google Blog Search\n",
    "Google My Business\n",
    "Google Business App\n",
    "Google Business Insights\n",
    "Google Business Listings\n",
    "Google My Business App\n",
    "Google My Business Insights\n",
    "Google My Business Listings\n",
    "Google My Business Profiles\n",
    "Google Business Profiles\n",
    "Google Cache\n",
    "Google Caffeine\n",
    "Google Changes\n",
    "Google Checkout\n",
    "Google Dance\n",
    "Google Day\n",
    "Google Desktop\n",
    "Google Disavow Tool\n",
    "Google Discover\n",
    "Google Doodle\n",
    "Google Earth\n",
    "Google Fiber\n",
    "Google Finance\n",
    "Google Glass\n",
    "Google Helpful Content Update\n",
    "Google Home\n",
    "Google Home Page\n",
    "Google Images\n",
    "Google Instant\n",
    "Google Keyword Tool\n",
    "Knowledge Graph\n",
    "Google Lens\n",
    "Google Local\n",
    "Google Local Business Center\n",
    "Google Local Maps\n",
    "Google Local Pack\n",
    "Google Local Panel\n",
    "Google Local Algorithm\n",
    "Google Local Algorithm Update\n",
    "Google Logo\n",
    "Google Maps\n",
    "Google Maps App\n",
    "Google Maps Business\n",
    "Google Maps Search\n",
    "Google Medic Update\n",
    "Google Merchant Center\n",
    "Google Mobile\n",
    "Google Mobile Index\n",
    "Google News\n",
    "Google News Publishers\n",
    "Google Office\n",
    "Google Page Experience Update\n",
    "Google PageRank Update\n",
    "Google Pages\n",
    "Google Pagespeed Insights\n",
    "Google Panda Update\n",
    "Google Partner\n",
    "Google Patent\n",
    "Google Penguin Update\n",
    "Google People Search\n",
    "Google Places\n",
    "Google Play\n",
    "Google Plus\n",
    "Google Plus Local\n",
    "Google Product Reviews Update\n",
    "Google Product Search\n",
    "Google Rankings\n",
    "Google Reader\n",
    "Google Real Time\n",
    "Google Results\n",
    "Google Reviews Update\n",
    "Google Rich Results\n",
    "Google Sandbox\n",
    "Google Search\n",
    "Google Search Analytics\n",
    "Google Search App\n",
    "Google Search Box\n",
    "Google Search Bug\n",
    "Google Search Console\n",
    "Google Search Console API\n",
    "Google Search Console Data\n",
    "Google Search Console Reports\n",
    "Google Search Results\n",
    "Google Search Testing\n",
    "Google Self Driving Car\n",
    "Google Shopping\n",
    "Google Shopping Ads\n",
    "Google Sitemaps\n",
    "Google Spam\n",
    "Google Stories\n",
    "Google Street View\n",
    "Google Suggest\n",
    "Google Tests\n",
    "Google Toolbar\n",
    "Google Translate\n",
    "Google Trends\n",
    "Google Videos\n",
    "Google Video Search\n",
    "Google Voice Search\n",
    "Google Webmaster Central\n",
    "Google Webmaster Conference\n",
    "Google Webmaster Team\n",
    "Google Webmaster Report\n",
    "Google Webmaster Tools\n",
    "Google Webmaster\n",
    "Google.com\n",
    "Googlebot\n",
    "Googleguy\n",
    "Googleplex\n",
    "Googlers\n",
    "Guest Blogging\n",
    "Hacked\n",
    "Headers\n",
    "Home Page\n",
    "Hosting\n",
    "Hreflang\n",
    "HTML5\n",
    "Image Carousel\n",
    "Google Image Search\n",
    "Image Search\n",
    "Images\n",
    "Indexing\n",
    "IndexNow\n",
    "Internal Links\n",
    "Internet Explorer\n",
    "iOS\n",
    "IP Address\n",
    "iPhone\n",
    "JavaScript\n",
    "John Mueller\n",
    "Keyword Density\n",
    "Keyword Planner\n",
    "Keywords\n",
    "Knowledge Panel\n",
    "Knowledte Panel\n",
    "Landing Pages\n",
    "Links\n",
    "Link Building\n",
    "Google Link Spam Update\n",
    "Google Local Business\n",
    "Local Knowledge Panel\n",
    "Local Listings\n",
    "Local Pack\n",
    "Local Results\n",
    "Google Local Results\n",
    "Google Local Search\n",
    "Google Local Service Ads\n",
    "Location\n",
    "Logo\n",
    "Low Quality\n",
    "AI\n",
    "Machine Learning\n",
    "Malware\n",
    "Manual Actions\n",
    "Marissa Mayer\n",
    "Markup\n",
    "Martin Splitt\n",
    "Matt Cutts\n",
    "Meta\n",
    "Meta Descriptions\n",
    "Meta Tag\n",
    "Microsoft\n",
    "Microsoft AdCenter\n",
    "Microsoft Advertising\n",
    "Microsoft Bing\n",
    "Microsoft Live Search\n",
    "Microsoft Search\n",
    "Mobile Friendly\n",
    "Mobile Friendly Algorithm\n",
    "Mobile Index\n",
    "Mobile Indexing\n",
    "Mobile Results\n",
    "Mountain View\n",
    "Moz\n",
    "Mozilla\n",
    "MSN\n",
    "MSN AdCenter\n",
    "MSN Search Update\n",
    "MSN Search\n",
    "MSNbot\n",
    "Navigation Bar\n",
    "Negative SEO\n",
    "Nofollow\n",
    "Noindex\n",
    "Organic Results\n",
    "Organic Search\n",
    "Overture\n",
    "Page Experience\n",
    "PageRank\n",
    "Paid Links\n",
    "PDFs\n",
    "Penalty\n",
    "Performance Max\n",
    "Performance Report\n",
    "Pubcon\n",
    "Quality Content\n",
    "Quality Raters Guidelines\n",
    "Quality Score\n",
    "Rand Fishkin\n",
    "RankBrain\n",
    "Ranking Changes\n",
    "Ranking Factor\n",
    "Ranking Signal\n",
    "Rating\n",
    "Recipe\n",
    "Referrer\n",
    "Results Page\n",
    "Reviews\n",
    "Rich Snippets\n",
    "Robots.txt\n",
    "RSS\n",
    "Sandbox\n",
    "Scams\n",
    "Schema\n",
    "Search Ads\n",
    "Search Box\n",
    "Search Community\n",
    "Search Community Honors\n",
    "Search Engines\n",
    "Search Engine Friendly\n",
    "Search Engine Land\n",
    "Search Marketing\n",
    "Search Engine Roundtable\n",
    "Search Engine Watch\n",
    "Search Generative Experience\n",
    "Search History\n",
    "Search Quality\n",
    "Search Rankings\n",
    "Search Results\n",
    "Search Suggestions\n",
    "Selling Links\n",
    "SEM\n",
    "SEMPO\n",
    "SEO\n",
    "SEO Industry\n",
    "SEOMoz\n",
    "Sergey Brin\n",
    "Service Ads\n",
    "Shopify\n",
    "Shopping Ads\n",
    "Signals\n",
    "Site Command\n",
    "Sitelinks\n",
    "Sitemaps\n",
    "SMX\n",
    "Snippets\n",
    "Social Media\n",
    "Spam\n",
    "Spam Algorithm\n",
    "Google Speed Update\n",
    "Google Backlink Update\n",
    "SSL\n",
    "Status Code\n",
    "Structured Data\n",
    "Sundar Pichai\n",
    "Tags\n",
    "Targeting\n",
    "Text Ads\n",
    "Theory\n",
    "Title Tags\n",
    "Titles\n",
    "TLDs\n",
    "Topic\n",
    "Traffic\n",
    "Trending Searches\n",
    "Tweets\n",
    "Twitter\n",
    "Unnatural Links\n",
    "URLs\n",
    "URL Inspection Tool\n",
    "User Agent\n",
    "Videos\n",
    "Web Search\n",
    "Webmaster Central\n",
    "Webmaster Guidelines\n",
    "Webmaster Report\n",
    "Webmasters\n",
    "WebmasterWorld\n",
    "Webspam\n",
    "Widget\n",
    "Wikipedia\n",
    "Word Count\n",
    "Wordpress\n",
    "XML Sitemaps\n",
    "Yahoo\n",
    "Yahoo Directory\n",
    "Yahoo Publisher Network\n",
    "Yahoo Search\n",
    "Yahoo Search Marketing\n",
    "Yahoo Search Update\n",
    "Yahoo Site Explorer\n",
    "Yandex\n",
    "Yelp\n",
    "YouTube\n",
    "YouTube Videos\n",
    "Keyword Research\n",
    "Google Florida Update\n",
    "Google Toolbar PageRank Update\n",
    "Google Fred Update\n",
    "Google Farmer Update\n",
    "Google Maccabees Update\n",
    "Exact Match Domains\n",
    "Google Phantom Update\"\"\"\n",
    "\n",
    "PROMPT = f\"\"\"As an expert at SEO, I need your help to review a list of topics and organize them into relevant categories.\n",
    "\n",
    "Here are some examples you can use to understand the expected output:\n",
    "  Ad Units, Paid\n",
    "  Google Analytics, Analytics & Tools\n",
    "  Carousel, Search Results\n",
    "  Google Panda Update, Algorithm Update\n",
    "  Google Caffeine,\tAlgorithm\n",
    "  Google Penguin Update, Algorithm\n",
    "  Google Hummingbird Update, Algorithm\n",
    "  Google Finance, Google Products\n",
    "  Google Maps, Google Products\n",
    "  Google My Business, Local SEO\n",
    "  Firefox, Browsers\n",
    "  Google Chrome, Browsers\n",
    "  ChatGPT, Machine Learning\n",
    "  Google Lens, Google Products\n",
    "  Cloaking, SEO Tactics\n",
    "  Canonical,\tTechnical SEO\n",
    "  Google Search Console, Analytics & Tools\n",
    "\n",
    "\n",
    "Topics for Review:\n",
    "{ngrams}\n",
    "\n",
    "You MUST follow the following format for your response:\n",
    "<original ngram: text-only>, <category: singular proper-case text-only>\n",
    "<original ngram: text-only>, <category: singular proper-case text-only>\n",
    ". . .\n",
    "\n",
    "Please read the examples very carefully to try to unsderstand why each category was assigned before you begin.\n",
    "\n",
    "Begin!\"\"\"\n",
    "\n",
    "\n",
    "explanation = get_openai_response_chat(\n",
    "        PROMPT,\n",
    "        model=settings.OPENAI_LARGE_MODEL,\n",
    "        system_message=\"You are an expert at SEO History.\",\n",
    "    )\n",
    "\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import StringIO\n",
    "from io import StringIO\n",
    "\n",
    "# read in the csv file from string `explanation` using StringIO\n",
    "\n",
    "df = pd.read_csv(StringIO(explanation), names=['ngram', 'category'])\n",
    "\n",
    "df.to_csv('categories_gpt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380.33000000000004"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "730 * 0.521"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxonomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
