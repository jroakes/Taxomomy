{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_taxonomy\n",
    "\n",
    "filename = \"cais_data_expanded.csv\"\n",
    "brand_terms = [\n",
    "    \"cais\",\n",
    "    \"cais group\",\n",
    "    \"glas\",\n",
    "    \"glas funds\",\n",
    "    \"halo\",\n",
    "    \"halo investing\",\n",
    "    \"icapital\",\n",
    "    \"icapital network\",\n",
    "]\n",
    "website_subject = \"Alternate Investing Platform\"\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(\n",
    "    filename,\n",
    "    text_column=\"keyword\",\n",
    "    search_volume_column=\"search_volume\",\n",
    "    min_df=5,\n",
    "    brand_terms=brand_terms,\n",
    ")\n",
    "\n",
    "df.to_csv(\"cais_data_taxonomy.csv\", index=False)\n",
    "\n",
    "print(\"\\n\".join(taxonomy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_taxonomy\n",
    "\n",
    "filename = \"HM Raw Data.csv\"\n",
    "website_subject = \"Houston Methodist Hospital\"\n",
    "\n",
    "brand_terms = [\n",
    "    \"luke\",\n",
    "    \"lukes\",\n",
    "    \"md anderson\",\n",
    "    \"anderson\",\n",
    "    \"hca\",\n",
    "    \"stlukes\",\n",
    "    \"memorial hermann\",\n",
    "    \"hermann\",\n",
    "    \"herman\",\n",
    "    \"houston methodist\",\n",
    "    \"methodist\",\n",
    "    \"st joseph\",\n",
    "    \"joseph\",\n",
    "]\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(\n",
    "    filename,\n",
    "    website_subject=website_subject,\n",
    "    text_column=\"keyword\",\n",
    "    search_volume_column=\"search_volume\",\n",
    "    min_cluster_size=10,\n",
    "    min_samples=3,\n",
    "    limit_queries=3,\n",
    "    ngram_range=(1, 5),\n",
    "    min_df=10,\n",
    "    brand_terms=brand_terms,\n",
    ")\n",
    "\n",
    "\n",
    "df.to_csv(\"HM_Raw_Data_ngram_taxonomy2.csv\", index=False)\n",
    "print(\"\\n\".join(taxonomy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a GSC Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2023-07-21 08:59:41.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.searchconsole\u001b[0m:\u001b[36mload_gsc_account_data\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mCreating dataframe...\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.searchconsole\u001b[0m:\u001b[36mload_gsc_account_data\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mDataframe created.\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mGot Data. Dataframe shape: (2419, 7)\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m217\u001b[0m - \u001b[1mFiltering Query Data.\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mGot ngram frequency. Dataframe shape: (384, 2)\u001b[0m\n",
      "\u001b[32m2023-07-21 08:59:59.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mMerged Ngrams. Dataframe shape: (321, 4)\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:01.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mFinal score and filter length: 321\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:01.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1mGot ngram frequency. Dataframe shape: (321, 6)\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:01.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m224\u001b[0m - \u001b[1mGot query data as markdown. Length: 13888\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:01.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mUsing OpenAI API.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ngram_size    query  merged_frequency  frequency  search_volume     score\n",
      "0           1  lounger          1.000000   1.000000       1.000000  1.000000\n",
      "1           1     pool          0.154122   0.690695       0.836386  0.495254\n",
      "2           1     hole          0.014337   0.013106       0.560620  0.287479\n",
      "3           1    table          0.111111   0.328965       0.423304  0.267208\n",
      "4           1  outdoor          0.301075   0.250328       0.218655  0.259865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-21 09:00:10.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mReviewing OpenAI's work.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m254\u001b[0m - \u001b[1mGetting structure.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mAdding categories.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mGetting embeddings.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:17.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "Batches: 100%|██████████| 22/22 [00:02<00:00,  7.50it/s]\n",
      "\u001b[32m2023-07-21 09:00:21.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:21.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:22.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m496\u001b[0m - \u001b[1mGetting pairwise cosine similarity.\u001b[0m\n",
      "\u001b[32m2023-07-21 09:00:22.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m499\u001b[0m - \u001b[1mGetting cross-encoder similarity.\u001b[0m\n",
      "Getting cross-encoder similarity: 100%|██████████| 1384/1384 [04:04<00:00,  5.65it/s]\n",
      "\u001b[32m2023-07-21 09:04:29.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mcreate_taxonomy\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mDone.\u001b[0m\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'ledgeloungers_taxonomy.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m      5\u001b[0m website_subject \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLedge Lounger offers luxury pool & outdoor furniture designed to create perfect spaces for outdoor entertaining and relaxation.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m taxonomy, df, samples \u001b[39m=\u001b[39m create_taxonomy(\n\u001b[0;32m      8\u001b[0m     \u001b[39mproperty\u001b[39m,\n\u001b[0;32m      9\u001b[0m     website_subject\u001b[39m=\u001b[39mwebsite_subject,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     limit_queries_per_page\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m\"\u001b[39;49m\u001b[39mledgeloungers_taxonomy.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     21\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'ledgeloungers_taxonomy.csv'"
     ]
    }
   ],
   "source": [
    "from main import create_taxonomy\n",
    "\n",
    "brand_terms = [\"ledgeloungers\", \"ledge\"]\n",
    "property = \"sc-domain:ledgeloungers.com\"\n",
    "website_subject = \"Ledge Lounger offers luxury pool & outdoor furniture designed to create perfect spaces for outdoor entertaining and relaxation.\"\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(\n",
    "    property,\n",
    "    website_subject=website_subject,\n",
    "    days=30,\n",
    "    ngram_range=(1, 5),\n",
    "    cross_encoded=True,\n",
    "    min_df=5,\n",
    "    brand_terms=brand_terms,\n",
    "    limit_queries_per_page=5,\n",
    ")\n",
    "\n",
    "\n",
    "df.to_csv(\"ledgeloungers_taxonomy2.csv\", index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ledgeloungers_taxonomy2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-21 07:28:42.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 07:28:42.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-21 07:28:43.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 07:28:43.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lib.clustering import ClusterTopics\n",
    "\n",
    "df = pd.read_csv(\"ledgeloungers_taxonomy.csv\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "queries = list(set(df[\"query\"].tolist()))\n",
    "queries = [queries[idx] for idx in [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]]\n",
    "taxonomies = list(set(df[\"taxonomy\"].tolist()))\n",
    "\n",
    "cluster_model = ClusterTopics(cluster_categories=taxonomies)\n",
    "cluster_model.corpus = queries\n",
    "cluster_model.embeddings = cluster_model.get_embeddings(queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-21 07:28:49.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 07:28:49.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "category_embeddings = cluster_model.get_embeddings(taxonomies)\n",
    "query_embeddings = cluster_model.embeddings\n",
    "\n",
    "query_embeddings = query_embeddings / np.linalg.norm(query_embeddings, axis=1, keepdims=True)\n",
    "category_embeddings = category_embeddings / np.linalg.norm(category_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "cosine_similarity_matrix = cosine_similarity(query_embeddings, category_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = 10\n",
    "top_n = 5\n",
    "import settings\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/qnli-electra-base\")\n",
    "cross_encoder_pairs = []\n",
    "\n",
    "\n",
    "for idx, query in enumerate(queries):\n",
    "    #print(\"#\" * 50)\n",
    "    #print(f\"Query: {query}\")\n",
    "\n",
    "    #print(\"\\nCosine Similarity:\")\n",
    "    top_categories = np.argsort(cosine_similarity_matrix[idx])[-top_n:][::-1]\n",
    "    pairs = []\n",
    "    for i in top_categories:\n",
    "        #print(taxonomies[i], cosine_similarity_matrix[idx][i])\n",
    "        pairs.append((query, taxonomies[i]))\n",
    "    \n",
    "    cross_encoder_pairs.append(pairs)\n",
    "    #print()\n",
    "\n",
    "\n",
    "cross_encoder_similarity = np.array([\n",
    "            cross_encoder.predict(pairs).flatten()\n",
    "            for pairs in cross_encoder_pairs\n",
    "        ])\n",
    "\n",
    "for idx, query in enumerate(queries):\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Query: {query}\")\n",
    "\n",
    "    print(\"\\nCross-encoder Similarity:\")\n",
    "    \n",
    "    # Test cross_encoder_similarity scores for this query.  If all scores are high and similar, then the query is ambiguous.  If on score is considerably lower than the others, then the query is not ambiguous.\n",
    "    \n",
    "\n",
    "\n",
    "    top_category= np.argmin(cross_encoder_similarity[idx])\n",
    "    print(cross_encoder_pairs[idx][top_category][1], cross_encoder_similarity[idx][top_category])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: in the pool chairs\n",
      "Options:\n",
      "chairs pool chairs 7.287129\n",
      "pool furniture chairs 7.0691895\n",
      "pool furniture loungers 3.595707\n",
      "loungers pool loungers -2.3364563\n",
      "pool furniture accessories 2.3251443\n",
      "\n",
      "Best: chairs pool chairs, 7.287128925323486\n"
     ]
    }
   ],
   "source": [
    "import settings\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
    "\n",
    "query = \"in the pool chairs\"\n",
    "\n",
    "options = \"\"\"Chairs Pool Chairs\n",
    "Pool Furniture Chairs\n",
    "Pool Furniture Loungers\n",
    "Loungers Pool Loungers\n",
    "Pool Furniture Accessories\"\"\".split(\"\\n\")\n",
    "\n",
    "options = [o.lower() for o in options]\n",
    "\n",
    "cross_encoder_pairs = [(query, option) for option in options]\n",
    "\n",
    "cross_encoder_similarity = cross_encoder.predict(cross_encoder_pairs).flatten()\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Options:\")\n",
    "for idx, pair in enumerate(cross_encoder_pairs):\n",
    "    print(pair[1], cross_encoder_similarity[idx])\n",
    "\n",
    "print()\n",
    "print(f\"Best: {cross_encoder_pairs[np.argmax(cross_encoder_similarity)][1]}, {cross_encoder_similarity[np.argmax(cross_encoder_similarity)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jroak\\anaconda3\\envs\\taxonomyml\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2023-07-21 10:12:44.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:44.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mGetting embeddings.\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mUsing local embeddings\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:45.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUsing custom embedding model: all-MiniLM-L6-v2\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:46.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m496\u001b[0m - \u001b[1mGetting pairwise cosine similarity.\u001b[0m\n",
      "\u001b[32m2023-07-21 10:12:46.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.clustering\u001b[0m:\u001b[36mfit_pairwise_crossencoded\u001b[0m:\u001b[36m499\u001b[0m - \u001b[1mGetting cross-encoder similarity.\u001b[0m\n",
      "Getting cross-encoder similarity: 100%|██████████| 19/19 [00:01<00:00, 16.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from main import add_categories\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"ledgeloungers_taxonomy2.csv\")\n",
    "\n",
    "structure = list(set(df.taxonomy.tolist()))\n",
    "\n",
    "# Random sample of 10 df rows\n",
    "df = df.sample(20)\n",
    "\n",
    "df = add_categories(structure, df, \n",
    "                    cross_encoded=True, \n",
    "                    percentile_threshold=50,\n",
    "                    std_dev_threshold= 0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>taxonomy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>tanning chairs</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>luxury pools</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>lounger cleaning</td>\n",
       "      <td>Pool Furniture &gt; Loungers &gt; Chaise Loungers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>pool loungers</td>\n",
       "      <td>Pool Furniture &gt; Loungers &gt; Pool Loungers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>outdoor umbrella with lights</td>\n",
       "      <td>Pool Furniture &gt; Umbrellas &gt; Cantilever Umbrellas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>pool lounger</td>\n",
       "      <td>Pool Furniture &gt; Loungers &gt; Pool Loungers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>weather resistant cushions</td>\n",
       "      <td>Pool Furniture &gt; Accessories &gt; Cushions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>lounger chaise</td>\n",
       "      <td>Pool Furniture &gt; Loungers &gt; Chaise Loungers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>flat cushion</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>lounger signature chaise deep</td>\n",
       "      <td>Pool Furniture &gt; Loungers &gt; Signature Chaise L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>cornhole game</td>\n",
       "      <td>Outdoor Games &gt; Cornhole Sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>pool pillow float</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>lounger pillows</td>\n",
       "      <td>Pool Furniture &gt; Loungers &gt; Chaise Loungers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>loungers</td>\n",
       "      <td>Pool Furniture &gt; Loungers &gt; Chaise Loungers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>lounger cleaning</td>\n",
       "      <td>Pool Furniture &gt; Loungers &gt; Chaise Loungers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>lounger houston</td>\n",
       "      <td>Pool Furniture &gt; Loungers &gt; Signature Chaise L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>pool bench</td>\n",
       "      <td>Pool Furniture &gt; Loungers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>furniture</td>\n",
       "      <td>Outdoor Living &gt; Patio Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>round patio coffee table</td>\n",
       "      <td>Pool Furniture &gt; Tables &gt; Coffee Tables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>couch with ottoman</td>\n",
       "      <td>Outdoor Living &gt; Ottomans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              query  \\\n",
       "1390                 tanning chairs   \n",
       "1334                   luxury pools   \n",
       "133                lounger cleaning   \n",
       "595                   pool loungers   \n",
       "528    outdoor umbrella with lights   \n",
       "2296                   pool lounger   \n",
       "621      weather resistant cushions   \n",
       "439                  lounger chaise   \n",
       "1006                   flat cushion   \n",
       "2192  lounger signature chaise deep   \n",
       "106                   cornhole game   \n",
       "781               pool pillow float   \n",
       "2166                lounger pillows   \n",
       "1762                       loungers   \n",
       "467                lounger cleaning   \n",
       "970                 lounger houston   \n",
       "529                      pool bench   \n",
       "294                       furniture   \n",
       "577        round patio coffee table   \n",
       "746              couch with ottoman   \n",
       "\n",
       "                                               taxonomy  \n",
       "1390                                      Miscellaneous  \n",
       "1334                                      Miscellaneous  \n",
       "133         Pool Furniture > Loungers > Chaise Loungers  \n",
       "595           Pool Furniture > Loungers > Pool Loungers  \n",
       "528   Pool Furniture > Umbrellas > Cantilever Umbrellas  \n",
       "2296          Pool Furniture > Loungers > Pool Loungers  \n",
       "621             Pool Furniture > Accessories > Cushions  \n",
       "439         Pool Furniture > Loungers > Chaise Loungers  \n",
       "1006                                      Miscellaneous  \n",
       "2192  Pool Furniture > Loungers > Signature Chaise L...  \n",
       "106                       Outdoor Games > Cornhole Sets  \n",
       "781                                       Miscellaneous  \n",
       "2166        Pool Furniture > Loungers > Chaise Loungers  \n",
       "1762        Pool Furniture > Loungers > Chaise Loungers  \n",
       "467         Pool Furniture > Loungers > Chaise Loungers  \n",
       "970   Pool Furniture > Loungers > Signature Chaise L...  \n",
       "529                           Pool Furniture > Loungers  \n",
       "294                    Outdoor Living > Patio Furniture  \n",
       "577             Pool Furniture > Tables > Coffee Tables  \n",
       "746                           Outdoor Living > Ottomans  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['query', 'taxonomy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.api import get_openai_response_chat\n",
    "import settings\n",
    "from tqdm import tqdm\n",
    "\n",
    "for url, row in tqdm(by_url.iterrows(), total=by_url.shape[0]):\n",
    "    samples = \"\\n\".join(row[\"keyword\"][:10])\n",
    "\n",
    "    prompt = f\"\"\"As an expert at understanding search intent, \n",
    "    Please provide a decrtiptive subject for the page based on the provided Search Queries.\n",
    "\n",
    "    Search Queries:\n",
    "    {samples}\n",
    "\n",
    "    Subject: \"\"\"\n",
    "\n",
    "    explanation = get_openai_response_chat(\n",
    "        prompt,\n",
    "        model=settings.CLUSTER_DESCRIPTION_MODEL,\n",
    "        system_message=\"You are an expert at understanding the intent of Google searches.\",\n",
    "    )\n",
    "\n",
    "    samples = \", \".join(row[\"keyword\"][:10])\n",
    "    print(explanation)\n",
    "    print(samples)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxonomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
