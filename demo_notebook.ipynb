{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ngrams based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_taxonomy\n",
    "\n",
    "filename = \"cais_data_expanded.csv\"\n",
    "brand_terms = ['cais', 'cais group', 'glas', 'glas funds', 'halo', 'halo investing', 'icapital', 'icapital network']\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(filename,\n",
    "                                        text_column = \"keyword\",\n",
    "                                        search_volume_column = \"search_volume\",\n",
    "                                        taxonomy_model = \"openai\", # \"palm\" or \"openai\"\n",
    "                                        use_clustering = False,\n",
    "                                        ngram_range = (1, 6),\n",
    "                                        min_df = 5,\n",
    "                                        brand_terms = brand_terms)\n",
    "\n",
    "df.to_csv(\"cais_data_expanded_ngram_taxonomy.csv\", index=False)\n",
    "\n",
    "print(\"\\n\".join(taxonomy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Description based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using LLM descriptions of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_taxonomy, add_categories\n",
    "\n",
    "filename = \"cais_data.csv\"\n",
    "brand_terms = ['cais', 'cais group', 'glas', 'glas funds', 'halo', 'halo investing', 'icapital', 'icapital network']\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(filename,\n",
    "                                        text_column = \"keyword\",\n",
    "                                        search_volume_column = \"search_volume\",\n",
    "                                        taxonomy_model = \"openai\", # \"palm\" or \"openai\"\n",
    "                                        use_clustering = True,\n",
    "                                        use_llm_cluster_descriptions = True,\n",
    "                                        cluster_embeddings_model = \"openai\", # \"palm\", \"openai\", or \"local\"\n",
    "                                        min_cluster_size = 5,\n",
    "                                        min_samples = 2,\n",
    "                                        ngram_range = (1, 6),\n",
    "                                        min_df = 5,\n",
    "                                        brand_terms = brand_terms)\n",
    "\n",
    "\n",
    "df.to_csv(\"taxonomy_cluster_llm.csv\", index=False)\n",
    "print(\"\\n\".join(taxonomy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using c-tfidf ngrams for clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_taxonomy, add_categories\n",
    "\n",
    "filename = \"cais_data_expanded.csv\"\n",
    "brand_terms = ['cais', 'cais group', 'glas', 'glas funds', 'halo', 'halo investing', 'icapital', 'icapital network']\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(filename,\n",
    "                                        text_column = \"keyword\",\n",
    "                                        search_volume_column = \"search_volume\",\n",
    "                                        taxonomy_model = \"openai\", # \"palm\" or \"openai\"\n",
    "                                        use_clustering = True,\n",
    "                                        use_llm_cluster_descriptions = False,\n",
    "                                        cluster_embeddings_model = \"openai\", # \"palm\", \"openai\", or \"local\"\n",
    "                                        min_cluster_size = 20,\n",
    "                                        min_samples = 3,\n",
    "                                        ngram_range = (1, 6),\n",
    "                                        min_df = 5,\n",
    "                                        brand_terms = brand_terms)\n",
    "\n",
    "df.to_csv(\"cais_data_expanded_taxonomy.csv\", index=False)\n",
    "print(\"\\n\".join(taxonomy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jroak\\anaconda3\\envs\\taxonomy\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\jroak\\anaconda3\\envs\\taxonomy\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\jroak\\anaconda3\\envs\\taxonomy\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\jroak\\anaconda3\\envs\\taxonomy\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\jroak\\anaconda3\\envs\\taxonomy\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "\u001b[32m2023-07-11 10:33:39.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mget_data\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mFound URL column: url.\u001b[0m\n",
      "\u001b[32m2023-07-11 10:33:41.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mGot ngram frequency. Dataframe shape: (1862, 2)\u001b[0m\n",
      "\u001b[32m2023-07-11 10:33:41.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36mscore_and_filter_df\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mMerged Ngrams. Dataframe shape: (1768, 4)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from main import create_taxonomy, get_data, score_and_filter_df\n",
    "\n",
    "filename = \"HM Raw Data.csv\"\n",
    "brand_terms = ['luke', 'lukes', 'md anderson', 'anderson', 'hca', 'stlukes', 'memorial', 'memorial hermann', \n",
    "               'hermann', 'herman', 'houston methodist', 'methodist', 'st joseph', 'joseph']\n",
    "\n",
    "df, df_original = get_data(filename, \n",
    "                           text_column = \"keyword\", \n",
    "                           limit_queries = 5,\n",
    "                           brand_terms = brand_terms,\n",
    "                           search_volume_column = \"search_volume\")\n",
    "\n",
    "df = score_and_filter_df(df, min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_size</th>\n",
       "      <th>query</th>\n",
       "      <th>merged_frequency</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_volume</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cancer</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.763736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>houston</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851282</td>\n",
       "      <td>0.178151</td>\n",
       "      <td>0.589075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>symptoms</td>\n",
       "      <td>0.232339</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.407960</td>\n",
       "      <td>0.320149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hospital</td>\n",
       "      <td>0.289639</td>\n",
       "      <td>0.242604</td>\n",
       "      <td>0.277722</td>\n",
       "      <td>0.283680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>near</td>\n",
       "      <td>0.229984</td>\n",
       "      <td>0.176726</td>\n",
       "      <td>0.252694</td>\n",
       "      <td>0.241339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>doctor</td>\n",
       "      <td>0.408948</td>\n",
       "      <td>0.248521</td>\n",
       "      <td>0.022871</td>\n",
       "      <td>0.215910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>texas</td>\n",
       "      <td>0.234694</td>\n",
       "      <td>0.167653</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.161947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>cardiologist</td>\n",
       "      <td>0.299843</td>\n",
       "      <td>0.160947</td>\n",
       "      <td>0.007295</td>\n",
       "      <td>0.153569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>cancer symptoms</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.011834</td>\n",
       "      <td>0.279144</td>\n",
       "      <td>0.151346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>urgent care</td>\n",
       "      <td>0.130298</td>\n",
       "      <td>0.065483</td>\n",
       "      <td>0.162028</td>\n",
       "      <td>0.146163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.221350</td>\n",
       "      <td>0.134122</td>\n",
       "      <td>0.040909</td>\n",
       "      <td>0.131130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>care</td>\n",
       "      <td>0.047096</td>\n",
       "      <td>0.209862</td>\n",
       "      <td>0.210596</td>\n",
       "      <td>0.128846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>hospitals</td>\n",
       "      <td>0.075353</td>\n",
       "      <td>0.050493</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.128349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>woodlands</td>\n",
       "      <td>0.210361</td>\n",
       "      <td>0.166469</td>\n",
       "      <td>0.020023</td>\n",
       "      <td>0.115192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>colon cancer</td>\n",
       "      <td>0.069859</td>\n",
       "      <td>0.043787</td>\n",
       "      <td>0.152009</td>\n",
       "      <td>0.110934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>breast cancer</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.044135</td>\n",
       "      <td>0.093496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>obgyn</td>\n",
       "      <td>0.179749</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.092743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>colon</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.059172</td>\n",
       "      <td>0.162332</td>\n",
       "      <td>0.092155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>cardiology</td>\n",
       "      <td>0.176609</td>\n",
       "      <td>0.115976</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.091737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>directions</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.170849</td>\n",
       "      <td>0.090527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram_size            query  merged_frequency  frequency  search_volume  \\\n",
       "0            1           cancer          0.527473   1.000000       1.000000   \n",
       "1            1          houston          1.000000   0.851282       0.178151   \n",
       "2            1         symptoms          0.232339   0.128600       0.407960   \n",
       "3            1         hospital          0.289639   0.242604       0.277722   \n",
       "4            1             near          0.229984   0.176726       0.252694   \n",
       "5            1           doctor          0.408948   0.248521       0.022871   \n",
       "6            1            texas          0.234694   0.167653       0.089200   \n",
       "7            1     cardiologist          0.299843   0.160947       0.007295   \n",
       "8            2  cancer symptoms          0.023548   0.011834       0.279144   \n",
       "9            2      urgent care          0.130298   0.065483       0.162028   \n",
       "10           1        treatment          0.221350   0.134122       0.040909   \n",
       "11           1             care          0.047096   0.209862       0.210596   \n",
       "12           1        hospitals          0.075353   0.050493       0.181345   \n",
       "13           1        woodlands          0.210361   0.166469       0.020023   \n",
       "14           2     colon cancer          0.069859   0.043787       0.152009   \n",
       "15           2    breast cancer          0.142857   0.090335       0.044135   \n",
       "16           1            obgyn          0.179749   0.090335       0.005737   \n",
       "17           1            colon          0.021978   0.059172       0.162332   \n",
       "18           1       cardiology          0.176609   0.115976       0.006864   \n",
       "19           1       directions          0.010204   0.005128       0.170849   \n",
       "\n",
       "       score  \n",
       "0   0.763736  \n",
       "1   0.589075  \n",
       "2   0.320149  \n",
       "3   0.283680  \n",
       "4   0.241339  \n",
       "5   0.215910  \n",
       "6   0.161947  \n",
       "7   0.153569  \n",
       "8   0.151346  \n",
       "9   0.146163  \n",
       "10  0.131130  \n",
       "11  0.128846  \n",
       "12  0.128349  \n",
       "13  0.115192  \n",
       "14  0.110934  \n",
       "15  0.093496  \n",
       "16  0.092743  \n",
       "17  0.092155  \n",
       "18  0.091737  \n",
       "19  0.090527  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"score\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m.\u001b[39;49mhead()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_taxonomy, add_categories_clustered, add_categories\n",
    "import pandas as pd\n",
    "\n",
    "taxonomy = \"\"\"Alternative Investments > Alternative Assets\n",
    "Alternative Investments > Annuities\n",
    "Alternative Investments > Annuities > AIG Annuities\n",
    "Alternative Investments > Annuities > Jackson Annuities\n",
    "Alternative Investments > Annuities > Multi Year Guaranteed Annuity\n",
    "Alternative Investments > Distressed\n",
    "Alternative Investments > Distressed > Distressed Debt\n",
    "Alternative Investments > Distressed > Distressed Investing\n",
    "Alternative Investments > ETFs\n",
    "Alternative Investments > ETFs > Buffer ETFs\n",
    "Alternative Investments > ETFs > Defined Outcome ETFs\n",
    "Alternative Investments > Hedge Funds\n",
    "Alternative Investments > Hedge Funds > Distressed Hedge Funds\n",
    "Alternative Investments > Hedge Funds > Global Macro Hedge Fund\n",
    "Alternative Investments > Hedge Funds > Hedged Equity\n",
    "Alternative Investments > Private Equity\n",
    "Alternative Investments > Private Equity > Distressed Private Equity\n",
    "Alternative Investments > Private Equity > Evergreen Private Equity\n",
    "Alternative Investments > Private Equity > Secondary Private Equity\n",
    "Alternative Investments > Real Estate > Private Real Estate Market\n",
    "Alternative Investments > Real Estate > Unlisted REIT\n",
    "Alternative Investments > Strategies\n",
    "Alternative Investments > Structured Products\n",
    "Alternative Investments > Structured Products > Structured Equity Products\n",
    "Alternative Investments > Structured Products > Structured ETFs\n",
    "Alternative Investments > Structured Products > Structured Notes\n",
    "Events > Alternative Investment Summit\n",
    "Financial Services > Broker Dealer\n",
    "Financial Services > Financial Advisors\n",
    "Financial Services > Financing\n",
    "Financial Services > Investment Platforms\n",
    "Financial Services > Investment Platforms > Alternative Investment Platforms\n",
    "Financial Services > Investment Platforms > Independent Financial Advisor Platforms\n",
    "Financial Services > Investment Platforms > White Label Investment Platform\n",
    "Investing > Capital\n",
    "Investing > Capital > BDC Capital\n",
    "Investing > Capital > Capital REIT\n",
    "Investing > Capital > Private Capital\n",
    "Investing > Funds\n",
    "Investing > Funds > Alternative Investment Funds\n",
    "Investing > Funds > Hedge Funds\n",
    "Investing > Funds > Interval Fund\n",
    "Investing > Funds > Investment REITs\n",
    "Investing > Funds > Private Credit Fund\n",
    "Investing > Funds > Private Equity Funds\n",
    "Investing > Private Equity\n",
    "Investing > Private Equity > Capital\n",
    "Investing > Private Equity > Equity\n",
    "Investing > Private Equity > Firms\n",
    "Investing > Private Equity > Funds\n",
    "Investing > Real Estate \n",
    "Investing > Real Estate > Trusts\n",
    "Investing > Real Estate > Funds\n",
    "Investing > Strategies\n",
    "Investing > Strategies > 60 20 20 portfolio\n",
    "Investing > Strategies > 60 40\n",
    "Investing > Strategies > 60 40 simplified\n",
    "Investing > Strategies > Returns\n",
    "Investing > Strategies > Skew Negative\n",
    "Investing > Strategies > Skew Positive\n",
    "Regulations\n",
    "Regulations > Reg BI\n",
    "Technology\n",
    "Technology > Alternative Investment\n",
    "Technolgy > Software\n",
    "Technology > Platform APIs\n",
    "Technology > Fintech\n",
    "Miscellaneous\n",
    "Miscellaneous > Person\n",
    "Miscellaneous > Company\n",
    "Miscellaneous > Log in\n",
    "Miscellaneous > Sign up\n",
    "Miscellaneous > Contact\n",
    "Miscellaneous > Location\n",
    "Miscellaneous > CAIS\n",
    "Miscellaneous > Forge\n",
    "Miscellaneous > Halo\n",
    "Miscellaneous > iCapital\n",
    "Other\"\"\".split(\"\\n\")\n",
    "\n",
    "taxonomy = [t.strip() for t in taxonomy]\n",
    "\n",
    "filename = \"cais_data.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "df_result = add_categories_clustered(taxonomy, df, \n",
    "                         cluster_embeddings_model = \"openai\",\n",
    "                         min_cluster_size = 3,\n",
    "                         min_samples = 1,\n",
    "                         cluster_model = \"agglomerative\",\n",
    "                         match_col = \"keyword\")\n",
    "\n",
    "\n",
    "df_result.to_csv(\"cais_data_taxonomy_final_agg2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an expert classifier, we need your help to classify the keywords into the given categories.\n",
      "\n",
      "Categories:\n",
      "Alternative Assets\n",
      "Annuities\n",
      "AIG Annuities\n",
      "Jackson Annuities\n",
      "Multi Year Guaranteed Annuity\n",
      "Distressed\n",
      "Distressed Debt\n",
      "Distressed Investing\n",
      "ETFs\n",
      "Buffer ETFs\n",
      "Defined Outcome ETFs\n",
      "Hedge Funds\n",
      "Distressed Hedge Funds\n",
      "Global Macro Hedge Fund\n",
      "Hedged Equity\n",
      "Private Equity\n",
      "Distressed Private Equity\n",
      "Evergreen Private Equity\n",
      "Secondary Private Equity\n",
      "Real Estate\n",
      "Private Real Estate Market\n",
      "Unlisted REIT\n",
      "Strategies\n",
      "Structured Products\n",
      "Structured Equity Products\n",
      "Structured ETFs\n",
      "Structured Notes\n",
      "Alternative Investment Summit\n",
      "Broker Dealer\n",
      "Financial Advisors\n",
      "Financing\n",
      "Investment Platforms\n",
      "Alternative Investment Platforms\n",
      "Independent Financial Advisor Platforms\n",
      "White Label Investment Platform\n",
      "Capital\n",
      "BDC Capital\n",
      "Capital REIT\n",
      "Private Capital\n",
      "Funds\n",
      "Alternative Investment Funds\n",
      "Funds Hedge Funds\n",
      "Interval Fund\n",
      "Investment REITs\n",
      "Private Credit Fund\n",
      "Private Equity Funds\n",
      "Investing Private Equity\n",
      "Private Equity Capital\n",
      "Equity\n",
      "Firms\n",
      "Private Equity Funds\n",
      "Real Estate \n",
      "Trusts\n",
      "Real Estate Funds\n",
      "Investing Strategies\n",
      "60 20 20 portfolio\n",
      "60 40\n",
      "60 40 simplified\n",
      "Returns\n",
      "Skew Negative\n",
      "Skew Positive\n",
      "Regulations\n",
      "Reg BI\n",
      "Technology\n",
      "Alternative Investment\n",
      "Software\n",
      "Platform APIs\n",
      "Fintech\n",
      "Miscellaneous\n",
      "Person\n",
      "Company\n",
      "Log in\n",
      "Sign up\n",
      "Contact\n",
      "Location\n",
      "CAIS\n",
      "Forge\n",
      "Halo\n",
      "iCapital\n",
      "Other\n",
      "\n",
      "Keywords:\n",
      "oid insurance\n",
      "addepar cost\n",
      "andrew gosden apollo\n",
      "aig annuity agent login\n",
      "rockefeller investment management\n",
      "structured notes investment\n",
      "negative vs positive skew\n",
      "structured product investments\n",
      "alternative careers for financial advisors\n",
      "private equity multiples\n",
      "halo api\n",
      "what is a secondaries fund\n",
      "inflation tomorrow\n",
      "www mercer com\n",
      "fund platform\n",
      "s   p notes\n",
      "bb   t securities llc\n",
      "portfolio rate annuities\n",
      "charles schwab alternative investments\n",
      "portfolio investment solutions\n",
      "ares new york office\n",
      "mercer advisors careers\n",
      "alternatives to fidelity\n",
      "buffered etf risks\n",
      "portfolio company value creation\n",
      "logo halo\n",
      "los angeles alternative investment conference\n",
      "bluerock wealth management\n",
      "keebeck wealth management\n",
      "fidelity investments private client group\n",
      "private equity multiples 2022\n",
      "what is a structured note\n",
      "sec reg bi care obligation\n",
      "alumni ventures sec\n",
      "key private bank\n",
      "structure notes\n",
      "cais conference 2023\n",
      "reg bi components\n",
      "finra broker dealer for sale\n",
      "open end real estate fund\n",
      "women with cais\n",
      "icapital com\n",
      "how do structured notes work\n",
      "capital systems\n",
      "multi year guaranteed annuity rates\n",
      "security benefit eldridge\n",
      "alternative investments\n",
      "www pershing com netx360\n",
      "reit valuations\n",
      "evanston capital management\n",
      "jackson national advisor login\n",
      "monroe capital\n",
      "case alternative investments\n",
      "distressed private equity funds\n",
      "income structured notes\n",
      "ted koenig\n",
      "cais insurance\n",
      "alternatives online access\n",
      "top quartile private equity funds\n",
      "orion investment management\n",
      "investing in notes\n",
      "bridge annuity\n",
      "glass alternative\n",
      "income note\n",
      "ares wealth management\n",
      "jefferies asset management\n",
      "morningstar investment conference\n",
      "alternative investment education\n",
      "pershing a bny mellon company\n",
      "cais aum\n",
      "halo tech group\n",
      "fidelity portfolio visualizer\n",
      "non traded reits performance\n",
      "private equity secondary funds\n",
      "investing in distressed companies\n",
      "access investing\n",
      "distressed debt firms\n",
      "what is distressed credit\n",
      "finra cais reporting\n",
      "cais finra\n",
      "investing com\n",
      "guggenheim investment\n",
      "why 60 40 portfolio\n",
      "unlisted reit\n",
      "stages of investing\n",
      "private equity value creation\n",
      "simplified alternatives\n",
      "broker dealer finop\n",
      "investor pershing\n",
      "rockefeller capital\n",
      "alternative financial solutions\n",
      "pe fund performance\n",
      "aig annuities advisor login\n",
      "200 west jackson street\n",
      "investing api\n",
      "protected notes\n",
      "wealth management alternative investments\n",
      "best structured notes\n",
      "focus financial partners investor relations\n",
      "evergreen funding\n",
      "\n",
      "Please classify the keywords into the given categories. If you think a keyword does not belong to any of the categories, please select \"Miscellaneous\" option. Respond ONLY with the classification for each keyword on a separate line.  DO NOT include the keyword, we will match the keyword to the classification later.\n",
      "\n",
      "Begin!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:37, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Miscellaneous\\nMiscellaneous\\nPerson\\nAIG Annuities\\nCompany\\nStructured Notes\\nReturns\\nStructured Products\\nAlternative Assets\\nPrivate Equity\\nTechnology\\nSecondary Private Equity\\nMiscellaneous\\nCompany\\nInvestment Platforms\\nMiscellaneous\\nCompany\\nAnnuities\\nAlternative Assets\\nInvestment Platforms\\nCompany\\nCompany\\nAlternative Assets\\nBuffer ETFs\\nPrivate Equity\\nMiscellaneous\\nAlternative Investment Summit\\nCompany\\nCompany\\nCompany\\nPrivate Equity\\nStructured Notes\\nRegulations\\nCompany\\nCompany\\nStructured Notes\\nAlternative Investment Summit\\nRegulations\\nBroker Dealer\\nReal Estate\\nMiscellaneous\\nCompany\\nMiscellaneous\\nReal Estate\\nCompany\\nStructured Notes\\nCapital\\nMulti Year Guaranteed Annuity\\nCompany\\nAlternative Assets\\nTechnology\\nReal Estate\\nCompany\\nAIG Annuities\\nCompany\\nCompany\\nAlternative Assets\\nDistressed Private Equity\\nStructured Notes\\nPerson\\nMiscellaneous\\nAlternative Assets\\nInvestment Platforms\\nPrivate Equity Funds\\nCompany\\nInvesting Strategies\\nAnnuities\\nMiscellaneous\\nStructured Notes\\nCompany\\nCompany\\nAlternative Investment Summit\\nAlternative Assets\\nCompany\\nMiscellaneous\\nTechnology\\nReal Estate\\nCompany\\nJackson Annuities\\nCompany\\nAlternative Assets\\nDistressed Private Equity\\nStructured Notes\\nPerson\\nMiscellaneous\\nAlternative Assets\\nAlternative Assets\\nPrivate Equity Funds\\nCompany\\nInvesting Strategies\\nAnnuities\\nMiscellaneous\\nCompany\\nCompany\\nMiscellaneous\\nCompany\\nMiscellaneous\\nInvesting Strategies\\nCompany\\nInvesting Strategies\\nUnlisted REIT\\nInvesting Strategies\\nPrivate Equity\\nAlternative Assets\\nBroker Dealer\\nCompany\\nCompany\\nAlternative Assets\\nPrivate Equity\\nAIG Annuities\\nCompany\\nTechnology\\nStructured Notes\\nAlternative Assets\\nStructured Notes\\nCompany\\nCompany\\nPrivate Equity\\nInvesting in Distressed Companies\\nAlternative Assets\\nDistressed Debt\\nMiscellaneous\\nMiscellaneous\\nMiscellaneous\\nCompany\\nInvesting Strategies\\nUnlisted REIT\\nInvesting Strategies\\nPrivate Equity\\nAlternative Assets\\nBroker Dealer\\nCompany\\nCompany\\nAlternative Assets\\nPrivate Equity\\nAIG Annuities\\nCompany\\nTechnology\\nStructured Notes\\nAlternative Assets\\nStructured Notes\\nCompany\\nCompany\\nMiscellaneous'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.api import get_openai_response_chat\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "taxonomy = \"\"\"Alternative Investments > Alternative Assets\n",
    "Alternative Investments > Annuities\n",
    "Alternative Investments > Annuities > AIG Annuities\n",
    "Alternative Investments > Annuities > Jackson Annuities\n",
    "Alternative Investments > Annuities > Multi Year Guaranteed Annuity\n",
    "Alternative Investments > Distressed\n",
    "Alternative Investments > Distressed > Distressed Debt\n",
    "Alternative Investments > Distressed > Distressed Investing\n",
    "Alternative Investments > ETFs\n",
    "Alternative Investments > ETFs > Buffer ETFs\n",
    "Alternative Investments > ETFs > Defined Outcome ETFs\n",
    "Alternative Investments > Hedge Funds\n",
    "Alternative Investments > Hedge Funds > Distressed Hedge Funds\n",
    "Alternative Investments > Hedge Funds > Global Macro Hedge Fund\n",
    "Alternative Investments > Hedge Funds > Hedged Equity\n",
    "Alternative Investments > Private Equity\n",
    "Alternative Investments > Private Equity > Distressed Private Equity\n",
    "Alternative Investments > Private Equity > Evergreen Private Equity\n",
    "Alternative Investments > Private Equity > Secondary Private Equity\n",
    "Alternative Investments > Real Estate\n",
    "Alternative Investments > Real Estate > Private Real Estate Market\n",
    "Alternative Investments > Real Estate > Unlisted REIT\n",
    "Alternative Investments > Strategies\n",
    "Alternative Investments > Structured Products\n",
    "Alternative Investments > Structured Products > Structured Equity Products\n",
    "Alternative Investments > Structured Products > Structured ETFs\n",
    "Alternative Investments > Structured Products > Structured Notes\n",
    "Events > Alternative Investment Summit\n",
    "Financial Services > Broker Dealer\n",
    "Financial Services > Financial Advisors\n",
    "Financial Services > Financing\n",
    "Financial Services > Investment Platforms\n",
    "Financial Services > Investment Platforms > Alternative Investment Platforms\n",
    "Financial Services > Investment Platforms > Independent Financial Advisor Platforms\n",
    "Financial Services > Investment Platforms > White Label Investment Platform\n",
    "Investing > Capital\n",
    "Investing > Capital > BDC Capital\n",
    "Investing > Capital > Capital REIT\n",
    "Investing > Capital > Private Capital\n",
    "Investing > Funds\n",
    "Investing > Funds > Alternative Investment Funds\n",
    "Investing > Funds > Hedge Funds\n",
    "Investing > Funds > Interval Fund\n",
    "Investing > Funds > Investment REITs\n",
    "Investing > Funds > Private Credit Fund\n",
    "Investing > Funds > Private Equity Funds\n",
    "Investing > Private Equity\n",
    "Investing > Private Equity > Capital\n",
    "Investing > Private Equity > Equity\n",
    "Investing > Private Equity > Firms\n",
    "Investing > Private Equity > Funds\n",
    "Investing > Real Estate \n",
    "Investing > Real Estate > Trusts\n",
    "Investing > Real Estate > Funds\n",
    "Investing > Strategies\n",
    "Investing > Strategies > 60 20 20 portfolio\n",
    "Investing > Strategies > 60 40\n",
    "Investing > Strategies > 60 40 simplified\n",
    "Investing > Strategies > Returns\n",
    "Investing > Strategies > Skew Negative\n",
    "Investing > Strategies > Skew Positive\n",
    "Regulations\n",
    "Regulations > Reg BI\n",
    "Technology\n",
    "Technology > Alternative Investment\n",
    "Technol0gy > Software\n",
    "Technology > Platform APIs\n",
    "Technology > Fintech\n",
    "Miscellaneous\n",
    "Miscellaneous > Person\n",
    "Miscellaneous > Company\n",
    "Miscellaneous > Log in\n",
    "Miscellaneous > Sign up\n",
    "Miscellaneous > Contact\n",
    "Miscellaneous > Location\n",
    "Miscellaneous > CAIS\n",
    "Miscellaneous > Forge\n",
    "Miscellaneous > Halo\n",
    "Miscellaneous > iCapital\n",
    "Other\"\"\".split(\"\\n\")\n",
    "\n",
    "filename = \"cais_data.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "structure = taxonomy.copy()\n",
    "\n",
    "structure_parts = []\n",
    "for s in structure:\n",
    "        last_parts = s.split(\" > \")[-2:]\n",
    "\n",
    "        if last_parts[-1] not in structure_parts:\n",
    "            structure_parts.append(last_parts[-1])\n",
    "        else:\n",
    "            structure_parts.append(\" \".join(last_parts))\n",
    "\n",
    "structure_map = {p:s for p, s in zip(structure_parts, structure)}\n",
    "\n",
    "structure_map\n",
    "\n",
    "\n",
    "PROMPT = \"\"\"As an expert classifier, we need your help to classify the keywords into the given categories.\n",
    "\n",
    "Categories:\n",
    "{categories}\n",
    "\n",
    "Keywords:\n",
    "{keywords}\n",
    "\n",
    "Please classify the keywords into the given categories. If you think a keyword does not belong to any of the categories, please select \"Miscellaneous\" option. Respond ONLY with the classification for each keyword on a separate line.  DO NOT include the keyword, we will match the keyword to the classification later.\n",
    "\n",
    "Begin!\"\"\"\n",
    "\n",
    "categories = \"\\n\".join(structure_parts)\n",
    "keywords = list(set(df_result[\"keyword\"].tolist()))\n",
    "\n",
    "def batchify(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for batch in tqdm(batchify(keywords, batch_size)):\n",
    "    keyword_str = \"\\n\".join(batch)\n",
    "    prompt = PROMPT.format(categories=categories, keywords=keyword_str)\n",
    "    print(prompt)\n",
    "    response = get_openai_response_chat(prompt, system_message = \"You are an expert keyword classifier.\")\n",
    "    print('Got response')\n",
    "    break\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a GSC Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import create_taxonomy\n",
    "\n",
    "brand_terms = [\"Green Group\", \"greengroup\"]\n",
    "\n",
    "taxonomy, df, samples = create_taxonomy(\"sc-domain:greengroupcompanies.com\",\n",
    "                                        text_column = None,\n",
    "                                        search_volume_column = None,\n",
    "                                        taxonomy_model = \"openai\", # \"palm\" or \"openai\"\n",
    "                                        use_clustering = True,\n",
    "                                        days = 30,\n",
    "                                        ngram_range = (1, 6),\n",
    "                                        min_df = 2,\n",
    "                                        brand_terms = brand_terms,\n",
    "                                        limit_queries = 5)\n",
    "\n",
    "\n",
    "df.to_csv(\"greengroupcompanies_taxonomy.csv\", index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.api import get_openai_response_chat\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cais_whitespace.csv\")\n",
    "\n",
    "company_description = \"\"\"CAIS Group: Founded in 2009, CAIS, a fintech leader, is transforming the world of alternative investing. For independent financial advisors, CAIS provides access, education, and operational efficiency they can use to transact at scale and capture more wallet share. For asset managers, CAIS can help build their distribution network, capture new business, and cultivate relationships with independent financial advisors\"\"\"\n",
    "\n",
    "PROMPT = \"\"\"As an expert content strategist, please review the following search queries dealing with {taxonomy} and give me back the 1-3 best topic ideas along with the search queries for each topic.\n",
    "\n",
    "Please include topics that would be relevant to the audience of a company with the following descripiton:\n",
    "{description}\n",
    "\n",
    "The search query data is below in the format `<query> - <search volume>\\n`:\n",
    "{data}\n",
    "\n",
    "To do a good job, you should consider the following:\n",
    "* The topic should be relevant to the audience of the company\n",
    "* The topic should be something that the company can write about\n",
    "* The topic MUST be relevant to more than one of the provided queries\n",
    "* The topic keywords supplied in your output MUST be from the provided search queries\n",
    "* If you are not sure about a topic or there are not enough queries, set the topic, Description, and Keywords to `None`\n",
    "\n",
    "Your response should be EXACTLY in the following format with a space between each result:\n",
    "Topic: <topic>\n",
    "Description: <Description of topic - one sentence>\n",
    "Audience: <Audience this topic is relevant to - comma-separated list>\n",
    "Keywords: <keywords this topic covers from the search queries - comma-separated list>\n",
    "\n",
    "Begin!\"\"\"\n",
    "\n",
    "# Lowercase and strip whitespace from queries\n",
    "df[\"query\"] = df[\"query\"].str.lower().str.strip()\n",
    "\n",
    "# Remove commas from search volume\n",
    "df[\"search_volume\"] = df[\"search_volume\"].astype(str).fillna(\"0\")\n",
    "df[\"search_volume\"] = df[\"search_volume\"].str.replace(\",\", \"\")\n",
    "\n",
    "# Fillna on search volume\n",
    "df[\"search_volume\"] = df[\"search_volume\"].fillna(0).astype(int)\n",
    "\n",
    "# Map of query to search volume\n",
    "search_volume_mapping = df.set_index(\"query\")[\"search_volume\"].to_dict()\n",
    "taxonomies = df.groupby(\"taxonomy\").apply(lambda x: \"\\n\".join([f\"{keyword} - {sv}\" for keyword, sv in zip(x[\"query\"].tolist(), x[\"search_volume\"].tolist())])).to_dict()\n",
    "results = []\n",
    "\n",
    "response_template = {'taxonomy': None, 'topic': None, 'description': None, 'audience': None, 'keywords': None, 'search_volume': None}\n",
    "\n",
    "for taxonomy, data in tqdm(taxonomies.items(), total=len(taxonomies)):\n",
    "    resp = get_openai_response_chat(PROMPT.format(taxonomy=taxonomy, description=company_description, data=data))\n",
    "\n",
    "    # Extract the Topic, Description, and Keywords from the response\n",
    "    resp_data = response_template.copy()\n",
    "    resp_data['taxonomy'] = taxonomy\n",
    "\n",
    "    for line in resp.split(\"\\n\"):\n",
    "        if line.startswith(\"Topic:\"):\n",
    "            resp_data['topic'] = line.replace(\"Topic: \", \"\")\n",
    "        elif line.startswith(\"Description:\"):\n",
    "            resp_data['description'] = line.replace(\"Description: \", \"\")\n",
    "        elif line.startswith(\"Audience:\"):\n",
    "            resp_data['audience'] = line.replace(\"Audience: \", \"\")\n",
    "        elif line.startswith(\"Keywords:\"):\n",
    "            keywords = line.replace(\"Keywords: \", \"\")\n",
    "            resp_data['keywords'] = keywords\n",
    "            resp_data['search_volume'] = sum([search_volume_mapping.get(keyword.lower().strip(), 0) for keyword in keywords.split(\",\")])\n",
    "            if resp_data['topic'] != \"None\" and resp_data['search_volume'] > 0:\n",
    "                results.append(resp_data)\n",
    "            resp_data = response_template.copy()\n",
    "            resp_data['taxonomy'] = taxonomy\n",
    "\n",
    "\n",
    "# Create a dataframe from the results\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"cais_taxonomy_whitespace_chat_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxonomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
